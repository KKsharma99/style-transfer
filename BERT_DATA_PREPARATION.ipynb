{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME\n",
    "#from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear\n",
    "\n",
    "from bertviz.bertviz import attention, visualization\n",
    "from bertviz.bertviz.pytorch_pretrained_bert import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "bert_classifier_model_dir = \"models/\" ## Path of BERT classifier model path\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "logger.info(\"device: {}, n_gpu {}\".format(device, n_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "data_dir = os.getcwd()\n",
    "dataset = \"data\" # amazon / yelp / imagecaption\n",
    "train_0 = os.path.join(data_dir ,\"{}/train/trump.txt\".format(dataset))\n",
    "train_1 = os.path.join(data_dir,\"{}/train/en.txt\".format(dataset))\n",
    "test_0 = os.path.join(data_dir,\"{}/test/trump.txt\".format(dataset))\n",
    "test_1 = os.path.join(data_dir,\"{}/test/en.txt\".format(dataset))\n",
    "dev_0 = os.path.join(data_dir,\"{}/dev/trump.txt\".format(dataset))\n",
    "dev_1 = os.path.join(data_dir,\"{}/dev/en.txt\".format(dataset))\n",
    "reference_0 = os.path.join(data_dir,\"./{}/reference_0.txt\".format(dataset))\n",
    "reference_1 = os.path.join(data_dir,\"./{}/reference_1.txt\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "data_dir = os.getcwd()\n",
    "dataset = \"data\" # amazon / yelp / imagecaption\n",
    "train_0_out = os.path.join(data_dir ,\"{}/processed_files_with_bert_with_best_head/sentiment_train_0.txt\".format(dataset))\n",
    "train_1_out = os.path.join(data_dir,\"{}/processed_files_with_bert_with_best_head/sentiment_train_1.txt\".format(dataset))\n",
    "test_0_out = os.path.join(data_dir,\"{}/processed_files_with_bert_with_best_head/sentiment_test_0.txt\".format(dataset))\n",
    "test_1_out = os.path.join(data_dir,\"{}/processed_files_with_bert_with_best_head/sentiment_test_1.txt\".format(dataset))\n",
    "dev_0_out = os.path.join(data_dir,\"{}/processed_files_with_bert_with_best_head/sentiment_dev_0.txt\".format(dataset))\n",
    "dev_1_out = os.path.join(data_dir,\"{}/processed_files_with_bert_with_best_head/sentiment_dev_1.txt\".format(dataset))\n",
    "reference_0_out = os.path.join(data_dir,\"{}/processed_files_with_bert_with_best_head/reference_0.txt\".format(dataset))\n",
    "reference_1_out = os.path.join(data_dir,\"{}/processed_files_with_bert_with_best_head/reference_1.txt\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model for performing Classification\n",
    "model_cls = BertForSequenceClassification.from_pretrained(bert_classifier_model_dir, num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model_cls.to(device)\n",
    "model_cls.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model to get the attention weights of all the heads\n",
    "model = BertModel.from_pretrained(bert_classifier_model_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len=512 # Maximum sequence length \n",
    "sm = torch.nn.Softmax(dim=-1) ## Softmax over the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words=['is','are','was','were','has','have','had','a','an','the','this','that','these','those','there','how','i','we',\n",
    "             'he','she','it','they','them','their','his','him','her','us','our', 'and','in','my','your','you', 'will', 'shall']\n",
    "common_words_tokens = tokenizer.convert_tokens_to_ids(common_words)\n",
    "not_to_remove_ids = tokenizer.convert_tokens_to_ids([\"[CLS]\",\"[SEP]\", \".\", \"?\", \"!\"])\n",
    "not_to_remove_ids += common_words_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, encoding = \"ISO-8859-1\") as fp:\n",
    "        data = fp.read().splitlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_file(original_sentences,processed_sentences, output_file, sentiment=\"<POS>\"):\n",
    "    with open(output_file,\"w\") as fp:\n",
    "        for sen1,sen2 in zip(original_sentences,processed_sentences):\n",
    "            if sen1 != None and sen2 != None:\n",
    "                str1 = sentiment + \" <CON_START> \" + sen2 + \" <START> \" + sen1 + \" <END>\\n\"\n",
    "                fp.write(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ref_output_file(processed_sentences, output_file, sentiment=\"<POS>\"):\n",
    "    with open(output_file,\"w\") as fp:\n",
    "        for sen in tqdm(processed_sentences):\n",
    "            if sen != None:\n",
    "                str1 = sentiment + \" <CON_START> \" + sen + \" <START>\\n\"\n",
    "                fp.write(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate_files(inp_files, out_files):\n",
    "    with open(out_files,\"w\") as fp:\n",
    "        for file in inp_files:\n",
    "            with open(file) as f:\n",
    "                for line in f:\n",
    "                    fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_attn_examples(input_sentences, layer, head, bs=128):\n",
    "    \"\"\"\n",
    "    Returns Attention weights for selected Layer and Head along with ids and tokens\n",
    "    of the input_sentence\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    ids_to_decode = [None for k in range(len(input_sentences))]\n",
    "    tokens_to_decode = [None for k in range(len(input_sentences))]\n",
    "    segment_ids = []\n",
    "    input_masks = []\n",
    "    attention_weights = [None for z in input_sentences]\n",
    "    ## BERT pre-processing\n",
    "    for j,sen in enumerate(tqdm(input_sentences)):\n",
    "        \n",
    "        text_tokens = tokenizer.tokenize(sen)\n",
    "        if len(text_tokens) >= max_seq_len-2:\n",
    "            text_tokens = text_tokens[:max_seq_len-4]\n",
    "        tokens = [\"[CLS]\"] + text_tokens + [\"[SEP]\"]\n",
    "        tokens_to_decode[j] = tokens\n",
    "        temp_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        ids_to_decode[j] = temp_ids\n",
    "        input_mask = [1] * len(temp_ids)\n",
    "        segment_id = [0] * len(temp_ids)\n",
    "        padding = [0] * (max_seq_len - len(temp_ids))\n",
    "        \n",
    "        \n",
    "        temp_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_id += padding\n",
    "        \n",
    "        ids.append(temp_ids)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "    \n",
    "    # Convert Ids to Torch Tensors\n",
    "    ids = torch.tensor(ids) \n",
    "    segment_ids = torch.tensor(segment_ids)\n",
    "    input_masks = torch.tensor(input_masks)\n",
    "    \n",
    "    steps = len(ids) // bs\n",
    "    \n",
    "    for i in trange(steps+1):\n",
    "        if i == steps:\n",
    "            temp_ids = ids[i * bs : len(ids)]\n",
    "            temp_segment_ids = segment_ids[i * bs: len(ids)]\n",
    "            temp_input_masks = input_masks[i * bs: len(ids)]\n",
    "        else:\n",
    "            temp_ids = ids[i * bs : i * bs + bs]\n",
    "            temp_segment_ids = segment_ids[i * bs: i * bs + bs]\n",
    "            temp_input_masks = input_masks[i * bs: i * bs + bs]\n",
    "        \n",
    "        temp_ids = temp_ids.to(device)\n",
    "        temp_segment_ids = temp_segment_ids.to(device)\n",
    "        temp_input_masks = temp_input_masks.to(device)\n",
    "        with torch.no_grad():\n",
    "             _, _, attn = model(temp_ids, temp_segment_ids, temp_input_masks)\n",
    "        # Concate Attention weights\n",
    "        for j in range(len(attn[layer]['attn_probs'])):\n",
    "            attention_weights[i * bs + j] = (attn[layer]['attn_probs'][j][head][0]).to('cpu')\n",
    "    \n",
    "    return attention_weights, ids_to_decode, tokens_to_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(aw, ids_to_decode, tokens_to_decode):\n",
    "    out_sen = [None for i in range(len(aw))]\n",
    "    for i in trange(len(aw)):\n",
    "        #topv, topi = aw[i].topk(len(inps_tokens[i]))\n",
    "        topv, topi = aw[i].topk(ids_to_decode[i].index(0))\n",
    "        topi = topi.tolist()\n",
    "        topv = topv.tolist()\n",
    "        #print(i,train_0[i])\n",
    "        #print(tokens_to_decode[i])\n",
    "        #print(\"Original Top Indexes = {}\".format(topi))\n",
    "        topi = [topi[j] for j in range(len(topi)) if ids_to_decode[i][topi[j]] not in not_to_remove_ids] # remove noun and common words\n",
    "        #print(\"After removing Nouns = {}\".format(topi))\n",
    "        topi = [topi[j] for j in range(len(topi)) if \"##\" not in tokens_to_decode[i][topi[j]]] # Remove half words\n",
    "        #print(\"After removing Half-words = {}\".format(topi))\n",
    "\n",
    "        if (len(topi) < 4 and len(topi) > 0):\n",
    "            topi = [topi[0]]\n",
    "        elif(len(topi) < 8):\n",
    "            topi = topi[:2]\n",
    "        else:\n",
    "            topi = topi[:3]\n",
    "\n",
    "        #print(\"Final Topi = {}\".format(topi))\n",
    "        final_indexes = []\n",
    "        count = 0\n",
    "        count1 = 0\n",
    "        #print(ids_to_decode[i], tokens_to_decode[i])\n",
    "        while ids_to_decode[i][count] != 0:\n",
    "            if count in topi:\n",
    "                while ids_to_decode[i][count + count1 + 1] != 0:\n",
    "                    if \"##\" in tokens_to_decode[i][count + count1 + 1]:\n",
    "                        count1 += 1\n",
    "                    else:\n",
    "                        break\n",
    "                count += count1\n",
    "                count1 = 0\n",
    "            else:\n",
    "                final_indexes.append(ids_to_decode[i][count])\n",
    "            count += 1\n",
    "\n",
    "        #print(final_indexes)\n",
    "        temp_out_sen = tokenizer.convert_ids_to_tokens(final_indexes)\n",
    "        temp_out_sen = \" \".join(temp_out_sen).replace(\" ##\", \"\").replace(\"[CLS]\",\"\").replace(\"[SEP]\",\"\")\n",
    "        #print(temp_out_sen, \"\\n\\n\")\n",
    "        out_sen[i] = temp_out_sen.strip()\n",
    "    \n",
    "    return out_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0_data = read_file(train_0)\n",
    "train_1_data = read_file(train_1)\n",
    "dev_0_data = read_file(dev_0)\n",
    "dev_1_data = read_file(dev_1)\n",
    "test_0_data = read_file(test_0)\n",
    "test_1_data = read_file(test_1)\n",
    "# ref_0_data = read_file(reference_0)\n",
    "# ref_1_data = read_file(reference_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13711 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 64/13711 [00:00<00:21, 639.32it/s]\u001b[A\n",
      "  1%|          | 134/13711 [00:00<00:20, 655.85it/s]\u001b[A\n",
      "  1%|▏         | 202/13711 [00:00<00:20, 658.65it/s]\u001b[A\n",
      "  2%|▏         | 278/13711 [00:00<00:19, 678.68it/s]\u001b[A\n",
      "  3%|▎         | 348/13711 [00:00<00:19, 677.71it/s]\u001b[A\n",
      "  3%|▎         | 420/13711 [00:00<00:19, 689.75it/s]\u001b[A\n",
      "  4%|▎         | 496/13711 [00:00<00:18, 704.36it/s]\u001b[A\n",
      "  4%|▍         | 577/13711 [00:00<00:17, 732.51it/s]\u001b[A\n",
      "  5%|▍         | 649/13711 [00:00<00:18, 725.16it/s]\u001b[A\n",
      "  5%|▌         | 720/13711 [00:01<00:18, 719.56it/s]\u001b[A\n",
      "  6%|▌         | 806/13711 [00:01<00:17, 756.49it/s]\u001b[A\n",
      "  6%|▋         | 882/13711 [00:01<00:17, 749.22it/s]\u001b[A\n",
      "  7%|▋         | 957/13711 [00:01<00:18, 695.03it/s]\u001b[A\n",
      "  7%|▋         | 1028/13711 [00:01<00:18, 696.93it/s]\u001b[A\n",
      "  8%|▊         | 1107/13711 [00:01<00:17, 722.31it/s]\u001b[A\n",
      "  9%|▊         | 1180/13711 [00:01<00:17, 721.76it/s]\u001b[A\n",
      "  9%|▉         | 1254/13711 [00:01<00:17, 724.36it/s]\u001b[A\n",
      " 10%|▉         | 1327/13711 [00:01<00:17, 703.49it/s]\u001b[A\n",
      " 10%|█         | 1400/13711 [00:01<00:17, 711.24it/s]\u001b[A\n",
      " 11%|█         | 1481/13711 [00:02<00:16, 736.45it/s]\u001b[A\n",
      " 11%|█▏        | 1556/13711 [00:02<00:16, 738.56it/s]\u001b[A\n",
      " 12%|█▏        | 1633/13711 [00:02<00:16, 746.44it/s]\u001b[A\n",
      " 12%|█▏        | 1713/13711 [00:02<00:15, 751.62it/s]\u001b[A\n",
      " 13%|█▎        | 1789/13711 [00:02<00:17, 664.34it/s]\u001b[A\n",
      " 14%|█▎        | 1858/13711 [00:02<00:18, 646.05it/s]\u001b[A\n",
      " 14%|█▍        | 1934/13711 [00:02<00:17, 675.69it/s]\u001b[A\n",
      " 15%|█▍        | 2008/13711 [00:02<00:16, 691.93it/s]\u001b[A\n",
      " 15%|█▌        | 2079/13711 [00:02<00:18, 645.21it/s]\u001b[A\n",
      " 16%|█▌        | 2145/13711 [00:03<00:18, 637.55it/s]\u001b[A\n",
      " 16%|█▌        | 2216/13711 [00:03<00:17, 656.29it/s]\u001b[A\n",
      " 17%|█▋        | 2285/13711 [00:03<00:17, 660.84it/s]\u001b[A\n",
      " 17%|█▋        | 2356/13711 [00:03<00:16, 674.38it/s]\u001b[A\n",
      " 18%|█▊        | 2424/13711 [00:03<00:16, 667.51it/s]\u001b[A\n",
      " 18%|█▊        | 2498/13711 [00:03<00:16, 686.56it/s]\u001b[A\n",
      " 19%|█▊        | 2568/13711 [00:03<00:16, 685.70it/s]\u001b[A\n",
      " 19%|█▉        | 2637/13711 [00:03<00:16, 680.16it/s]\u001b[A\n",
      " 20%|█▉        | 2706/13711 [00:03<00:17, 645.59it/s]\u001b[A\n",
      " 20%|██        | 2772/13711 [00:04<00:17, 636.87it/s]\u001b[A\n",
      " 21%|██        | 2837/13711 [00:04<00:17, 619.17it/s]\u001b[A\n",
      " 21%|██        | 2911/13711 [00:04<00:16, 650.05it/s]\u001b[A\n",
      " 22%|██▏       | 2980/13711 [00:04<00:16, 660.30it/s]\u001b[A\n",
      " 22%|██▏       | 3050/13711 [00:04<00:16, 665.93it/s]\u001b[A\n",
      " 23%|██▎       | 3117/13711 [00:04<00:16, 653.40it/s]\u001b[A\n",
      " 23%|██▎       | 3190/13711 [00:04<00:15, 669.66it/s]\u001b[A\n",
      " 24%|██▍       | 3271/13711 [00:04<00:14, 706.15it/s]\u001b[A\n",
      " 24%|██▍       | 3343/13711 [00:04<00:15, 663.68it/s]\u001b[A\n",
      " 25%|██▍       | 3411/13711 [00:04<00:16, 634.94it/s]\u001b[A\n",
      " 25%|██▌       | 3484/13711 [00:05<00:15, 660.24it/s]\u001b[A\n",
      " 26%|██▌       | 3551/13711 [00:05<00:15, 644.25it/s]\u001b[A\n",
      " 26%|██▋       | 3617/13711 [00:05<00:15, 647.98it/s]\u001b[A\n",
      " 27%|██▋       | 3683/13711 [00:05<00:16, 617.44it/s]\u001b[A\n",
      " 27%|██▋       | 3750/13711 [00:05<00:15, 627.61it/s]\u001b[A\n",
      " 28%|██▊       | 3814/13711 [00:05<00:15, 630.45it/s]\u001b[A\n",
      " 28%|██▊       | 3878/13711 [00:05<00:15, 632.85it/s]\u001b[A\n",
      " 29%|██▉       | 3945/13711 [00:05<00:15, 640.89it/s]\u001b[A\n",
      " 29%|██▉       | 4020/13711 [00:05<00:14, 669.51it/s]\u001b[A\n",
      " 30%|██▉       | 4102/13711 [00:06<00:13, 705.34it/s]\u001b[A\n",
      " 30%|███       | 4174/13711 [00:06<00:14, 657.54it/s]\u001b[A\n",
      " 31%|███       | 4241/13711 [00:06<00:14, 651.25it/s]\u001b[A\n",
      " 31%|███▏      | 4312/13711 [00:06<00:14, 667.12it/s]\u001b[A\n",
      " 32%|███▏      | 4384/13711 [00:06<00:13, 676.63it/s]\u001b[A\n",
      " 32%|███▏      | 4453/13711 [00:06<00:14, 649.08it/s]\u001b[A\n",
      " 33%|███▎      | 4519/13711 [00:06<00:14, 636.60it/s]\u001b[A\n",
      " 34%|███▎      | 4596/13711 [00:06<00:13, 665.43it/s]\u001b[A\n",
      " 34%|███▍      | 4680/13711 [00:06<00:12, 707.41it/s]\u001b[A\n",
      " 35%|███▍      | 4760/13711 [00:06<00:12, 731.23it/s]\u001b[A\n",
      " 35%|███▌      | 4835/13711 [00:07<00:12, 696.33it/s]\u001b[A\n",
      " 36%|███▌      | 4906/13711 [00:07<00:12, 691.17it/s]\u001b[A\n",
      " 36%|███▋      | 4982/13711 [00:07<00:12, 708.52it/s]\u001b[A\n",
      " 37%|███▋      | 5054/13711 [00:07<00:12, 679.33it/s]\u001b[A\n",
      " 37%|███▋      | 5126/13711 [00:07<00:12, 690.71it/s]\u001b[A\n",
      " 38%|███▊      | 5196/13711 [00:07<00:12, 680.51it/s]\u001b[A\n",
      " 38%|███▊      | 5265/13711 [00:07<00:12, 680.38it/s]\u001b[A\n",
      " 39%|███▉      | 5334/13711 [00:07<00:13, 613.69it/s]\u001b[A\n",
      " 39%|███▉      | 5405/13711 [00:07<00:13, 633.70it/s]\u001b[A\n",
      " 40%|███▉      | 5480/13711 [00:08<00:12, 664.31it/s]\u001b[A\n",
      " 41%|████      | 5555/13711 [00:08<00:11, 684.17it/s]\u001b[A\n",
      " 41%|████      | 5635/13711 [00:08<00:11, 715.11it/s]\u001b[A\n",
      " 42%|████▏     | 5721/13711 [00:08<00:10, 752.06it/s]\u001b[A\n",
      " 42%|████▏     | 5803/13711 [00:08<00:10, 771.03it/s]\u001b[A\n",
      " 43%|████▎     | 5882/13711 [00:08<00:10, 749.25it/s]\u001b[A\n",
      " 43%|████▎     | 5958/13711 [00:08<00:10, 725.53it/s]\u001b[A\n",
      " 44%|████▍     | 6041/13711 [00:08<00:10, 752.96it/s]\u001b[A\n",
      " 45%|████▍     | 6118/13711 [00:08<00:10, 750.09it/s]\u001b[A\n",
      " 45%|████▌     | 6194/13711 [00:09<00:11, 668.55it/s]\u001b[A\n",
      " 46%|████▌     | 6274/13711 [00:09<00:10, 702.14it/s]\u001b[A\n",
      " 46%|████▋     | 6347/13711 [00:09<00:11, 655.14it/s]\u001b[A\n",
      " 47%|████▋     | 6420/13711 [00:09<00:10, 670.55it/s]\u001b[A\n",
      " 47%|████▋     | 6489/13711 [00:09<00:10, 666.31it/s]\u001b[A\n",
      " 48%|████▊     | 6566/13711 [00:09<00:10, 690.21it/s]\u001b[A\n",
      " 48%|████▊     | 6636/13711 [00:09<00:10, 674.56it/s]\u001b[A\n",
      " 49%|████▉     | 6705/13711 [00:09<00:10, 641.00it/s]\u001b[A\n",
      " 49%|████▉     | 6770/13711 [00:09<00:10, 631.89it/s]\u001b[A\n",
      " 50%|████▉     | 6848/13711 [00:10<00:10, 654.30it/s]\u001b[A\n",
      " 50%|█████     | 6915/13711 [00:10<00:10, 641.67it/s]\u001b[A\n",
      " 51%|█████     | 6983/13711 [00:10<00:10, 650.52it/s]\u001b[A\n",
      " 51%|█████▏    | 7049/13711 [00:10<00:10, 648.45it/s]\u001b[A\n",
      " 52%|█████▏    | 7116/13711 [00:10<00:10, 653.05it/s]\u001b[A\n",
      " 52%|█████▏    | 7182/13711 [00:10<00:10, 638.92it/s]\u001b[A\n",
      " 53%|█████▎    | 7254/13711 [00:10<00:09, 660.30it/s]\u001b[A\n",
      " 53%|█████▎    | 7321/13711 [00:10<00:10, 625.37it/s]\u001b[A\n",
      " 54%|█████▍    | 7385/13711 [00:10<00:10, 628.15it/s]\u001b[A\n",
      " 54%|█████▍    | 7452/13711 [00:10<00:09, 638.82it/s]\u001b[A\n",
      " 55%|█████▍    | 7517/13711 [00:11<00:09, 619.83it/s]\u001b[A\n",
      " 55%|█████▌    | 7586/13711 [00:11<00:09, 636.15it/s]\u001b[A\n",
      " 56%|█████▌    | 7662/13711 [00:11<00:09, 667.86it/s]\u001b[A\n",
      " 56%|█████▋    | 7730/13711 [00:11<00:09, 661.09it/s]\u001b[A\n",
      " 57%|█████▋    | 7797/13711 [00:11<00:08, 659.62it/s]\u001b[A\n",
      " 57%|█████▋    | 7864/13711 [00:11<00:09, 646.64it/s]\u001b[A\n",
      " 58%|█████▊    | 7929/13711 [00:11<00:08, 645.95it/s]\u001b[A\n",
      " 58%|█████▊    | 8001/13711 [00:11<00:08, 663.89it/s]\u001b[A\n",
      " 59%|█████▉    | 8076/13711 [00:11<00:08, 684.68it/s]\u001b[A\n",
      " 59%|█████▉    | 8145/13711 [00:12<00:08, 679.06it/s]\u001b[A\n",
      " 60%|█████▉    | 8219/13711 [00:12<00:07, 693.24it/s]\u001b[A\n",
      " 60%|██████    | 8289/13711 [00:12<00:08, 661.52it/s]\u001b[A\n",
      " 61%|██████    | 8356/13711 [00:12<00:08, 621.60it/s]\u001b[A\n",
      " 62%|██████▏   | 8434/13711 [00:12<00:07, 661.20it/s]\u001b[A\n",
      " 62%|██████▏   | 8508/13711 [00:12<00:07, 675.62it/s]\u001b[A\n",
      " 63%|██████▎   | 8577/13711 [00:12<00:07, 664.61it/s]\u001b[A\n",
      " 63%|██████▎   | 8648/13711 [00:12<00:07, 677.17it/s]\u001b[A\n",
      " 64%|██████▎   | 8727/13711 [00:12<00:07, 706.50it/s]\u001b[A\n",
      " 64%|██████▍   | 8799/13711 [00:12<00:07, 697.94it/s]\u001b[A\n",
      " 65%|██████▍   | 8870/13711 [00:13<00:06, 692.08it/s]\u001b[A\n",
      " 65%|██████▌   | 8940/13711 [00:13<00:07, 659.40it/s]\u001b[A\n",
      " 66%|██████▌   | 9007/13711 [00:13<00:07, 620.10it/s]\u001b[A\n",
      " 66%|██████▌   | 9075/13711 [00:13<00:07, 632.11it/s]\u001b[A\n",
      " 67%|██████▋   | 9139/13711 [00:13<00:07, 613.71it/s]\u001b[A\n",
      " 67%|██████▋   | 9201/13711 [00:13<00:07, 605.10it/s]\u001b[A\n",
      " 68%|██████▊   | 9270/13711 [00:13<00:07, 628.24it/s]\u001b[A\n",
      " 68%|██████▊   | 9334/13711 [00:13<00:07, 623.31it/s]\u001b[A\n",
      " 69%|██████▊   | 9407/13711 [00:13<00:06, 646.73it/s]\u001b[A\n",
      " 69%|██████▉   | 9486/13711 [00:14<00:06, 678.68it/s]\u001b[A\n",
      " 70%|██████▉   | 9558/13711 [00:14<00:06, 689.99it/s]\u001b[A\n",
      " 70%|███████   | 9638/13711 [00:14<00:05, 717.25it/s]\u001b[A\n",
      " 71%|███████   | 9719/13711 [00:14<00:05, 739.63it/s]\u001b[A\n",
      " 71%|███████▏  | 9794/13711 [00:14<00:05, 740.27it/s]\u001b[A\n",
      " 72%|███████▏  | 9869/13711 [00:14<00:05, 658.98it/s]\u001b[A\n",
      " 72%|███████▏  | 9937/13711 [00:14<00:05, 647.92it/s]\u001b[A\n",
      " 73%|███████▎  | 10005/13711 [00:14<00:05, 655.65it/s]\u001b[A\n",
      " 73%|███████▎  | 10072/13711 [00:14<00:05, 637.84it/s]\u001b[A\n",
      " 74%|███████▍  | 10137/13711 [00:15<00:05, 631.48it/s]\u001b[A\n",
      " 75%|███████▍  | 10215/13711 [00:15<00:05, 667.58it/s]\u001b[A\n",
      " 75%|███████▍  | 10283/13711 [00:15<00:05, 647.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 10349/13711 [00:15<00:05, 647.23it/s]\u001b[A\n",
      " 76%|███████▌  | 10415/13711 [00:15<00:05, 583.11it/s]\u001b[A\n",
      " 76%|███████▋  | 10475/13711 [00:15<00:05, 566.94it/s]\u001b[A\n",
      " 77%|███████▋  | 10533/13711 [00:15<00:05, 565.96it/s]\u001b[A\n",
      " 77%|███████▋  | 10591/13711 [00:15<00:05, 524.45it/s]\u001b[A\n",
      " 78%|███████▊  | 10645/13711 [00:15<00:06, 493.15it/s]\u001b[A\n",
      " 78%|███████▊  | 10717/13711 [00:16<00:05, 543.25it/s]\u001b[A\n",
      " 79%|███████▉  | 10806/13711 [00:16<00:04, 614.06it/s]\u001b[A\n",
      " 79%|███████▉  | 10873/13711 [00:16<00:04, 605.91it/s]\u001b[A\n",
      " 80%|███████▉  | 10937/13711 [00:16<00:04, 599.64it/s]\u001b[A\n",
      " 80%|████████  | 11004/13711 [00:16<00:04, 616.05it/s]\u001b[A\n",
      " 81%|████████  | 11073/13711 [00:16<00:04, 635.28it/s]\u001b[A\n",
      " 81%|████████  | 11140/13711 [00:16<00:04, 641.47it/s]\u001b[A\n",
      " 82%|████████▏ | 11206/13711 [00:16<00:03, 645.11it/s]\u001b[A\n",
      " 82%|████████▏ | 11273/13711 [00:16<00:03, 651.26it/s]\u001b[A\n",
      " 83%|████████▎ | 11339/13711 [00:16<00:03, 628.32it/s]\u001b[A\n",
      " 83%|████████▎ | 11403/13711 [00:17<00:03, 624.00it/s]\u001b[A\n",
      " 84%|████████▎ | 11473/13711 [00:17<00:03, 640.24it/s]\u001b[A\n",
      " 84%|████████▍ | 11545/13711 [00:17<00:03, 657.24it/s]\u001b[A\n",
      " 85%|████████▍ | 11612/13711 [00:17<00:03, 653.51it/s]\u001b[A\n",
      " 85%|████████▌ | 11679/13711 [00:17<00:03, 657.96it/s]\u001b[A\n",
      " 86%|████████▌ | 11746/13711 [00:17<00:02, 660.88it/s]\u001b[A\n",
      " 86%|████████▌ | 11813/13711 [00:17<00:03, 631.55it/s]\u001b[A\n",
      " 87%|████████▋ | 11877/13711 [00:17<00:02, 632.91it/s]\u001b[A\n",
      " 87%|████████▋ | 11952/13711 [00:17<00:02, 663.90it/s]\u001b[A\n",
      " 88%|████████▊ | 12019/13711 [00:18<00:02, 659.04it/s]\u001b[A\n",
      " 88%|████████▊ | 12086/13711 [00:18<00:02, 661.94it/s]\u001b[A\n",
      " 89%|████████▊ | 12158/13711 [00:18<00:02, 677.34it/s]\u001b[A\n",
      " 89%|████████▉ | 12227/13711 [00:18<00:02, 674.28it/s]\u001b[A\n",
      " 90%|████████▉ | 12297/13711 [00:18<00:02, 680.61it/s]\u001b[A\n",
      " 90%|█████████ | 12366/13711 [00:18<00:02, 662.22it/s]\u001b[A\n",
      " 91%|█████████ | 12443/13711 [00:18<00:01, 685.72it/s]\u001b[A\n",
      " 91%|█████████▏| 12512/13711 [00:18<00:01, 602.86it/s]\u001b[A\n",
      " 92%|█████████▏| 12575/13711 [00:18<00:02, 562.98it/s]\u001b[A\n",
      " 92%|█████████▏| 12647/13711 [00:19<00:01, 602.03it/s]\u001b[A\n",
      " 93%|█████████▎| 12710/13711 [00:19<00:01, 582.24it/s]\u001b[A\n",
      " 93%|█████████▎| 12785/13711 [00:19<00:01, 622.52it/s]\u001b[A\n",
      " 94%|█████████▍| 12874/13711 [00:19<00:01, 680.46it/s]\u001b[A\n",
      " 94%|█████████▍| 12952/13711 [00:19<00:01, 706.27it/s]\u001b[A\n",
      " 95%|█████████▌| 13028/13711 [00:19<00:00, 714.77it/s]\u001b[A\n",
      " 96%|█████████▌| 13105/13711 [00:19<00:00, 726.12it/s]\u001b[A\n",
      " 96%|█████████▌| 13180/13711 [00:19<00:00, 732.61it/s]\u001b[A\n",
      " 97%|█████████▋| 13255/13711 [00:19<00:00, 710.78it/s]\u001b[A\n",
      " 97%|█████████▋| 13328/13711 [00:19<00:00, 714.23it/s]\u001b[A\n",
      " 98%|█████████▊| 13400/13711 [00:20<00:00, 694.58it/s]\u001b[A\n",
      " 98%|█████████▊| 13470/13711 [00:20<00:00, 691.75it/s]\u001b[A\n",
      " 99%|█████████▉| 13544/13711 [00:20<00:00, 704.43it/s]\u001b[A\n",
      " 99%|█████████▉| 13621/13711 [00:20<00:00, 721.21it/s]\u001b[A\n",
      "100%|██████████| 13711/13711 [00:20<00:00, 668.95it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/108 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f3ff39088933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_to_decode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_to_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_attn_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_0_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_0_out_sen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_to_decode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_to_decode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_0_out_sen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# with open('senlist.data', 'wb') as f:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     # store the data as binary data stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-feabfe818f77>\u001b[0m in \u001b[0;36mrun_attn_examples\u001b[0;34m(input_sentences, layer, head, bs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtemp_input_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_input_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m              \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_segment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_input_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Concate Attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attn_probs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/transformer-drg-style-transfer/bertviz/bertviz/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    725\u001b[0m         encoded_layers, attn_data_list = self.encoder(embedding_output,\n\u001b[1;32m    726\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/transformer-drg-style-transfer/bertviz/bertviz/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mattn_data_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0mattn_data_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/transformer-drg-style-transfer/bertviz/bertviz/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/transformer-drg-style-transfer/bertviz/bertviz/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/transformer-drg-style-transfer/bertviz/bertviz/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mnew_context_layer_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_head_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_0_data, layer=0, head=1, bs=128)\n",
    "train_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(train_0_data, train_0_out_sen, train_0_out, sentiment=\"<NEG>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_1_data, layer=0, head=1, bs=128)\n",
    "train_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(train_1_data, train_1_out_sen, train_1_out, sentiment=\"<POS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_0_data, layer=0, head=1, bs=128)\n",
    "dev_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(dev_0_data, dev_0_out_sen, dev_0_out, sentiment=\"<NEG>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_1_data, layer=0, head=1, bs=128)\n",
    "dev_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(dev_1_data, dev_1_out_sen, dev_1_out, sentiment=\"<POS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_1_data, layer=0, head=1, bs=128)\n",
    "test_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(test_1_data, test_1_out_sen, test_1_out, sentiment=\"<POS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_0_data, layer=0, head=1, bs=128)\n",
    "test_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "create_output_file(test_0_data, test_0_out_sen, test_0_out, sentiment=\"<NEG>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ref_1_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-deadc45add18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_to_decode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_to_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_attn_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_1_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mref_1_out_sen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_to_decode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_to_decode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcreate_ref_output_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_1_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_1_out_sen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_1_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<NEG>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ref_1_data' is not defined"
     ]
    }
   ],
   "source": [
    "# aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_1_data, layer=0, head=1, bs=128)\n",
    "# ref_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "# create_ref_output_file(ref_1_data, ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_0_data, layer=0, head=1, bs=128)\n",
    "# ref_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
    "# create_ref_output_file(ref_0_data, ref_0_out_sen, reference_0_out, sentiment=\"<POS>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
