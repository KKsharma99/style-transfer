{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "BERT_DATA_PREPARATION.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eP7J4rdok0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "43ac61f6-030a-44b1-846b-a200782576f6"
      },
      "source": [
        "! git clone https://github.com/tuanyuan2008/style-transfer.git\n",
        "% cd style-transfer\n",
        "! git pull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'style-transfer' already exists and is not an empty directory.\n",
            "/content/style-transfer\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 5 (delta 2), reused 5 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n",
            "From https://github.com/tuanyuan2008/style-transfer\n",
            "   d0ba8b0..bfcd667  master     -> origin/master\n",
            "Updating d0ba8b0..bfcd667\n",
            "Fast-forward\n",
            " data/processed_files/dev/en.txt      | 0\n",
            " data/processed_files/dev/trump.txt   | 0\n",
            " data/processed_files/test/en.txt     | 0\n",
            " data/processed_files/test/trump.txt  | 0\n",
            " data/processed_files/train/en.txt    | 0\n",
            " data/processed_files/train/trump.txt | 0\n",
            " 6 files changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 data/processed_files/dev/en.txt\n",
            " create mode 100644 data/processed_files/dev/trump.txt\n",
            " create mode 100644 data/processed_files/test/en.txt\n",
            " create mode 100644 data/processed_files/test/trump.txt\n",
            " create mode 100644 data/processed_files/train/en.txt\n",
            " create mode 100644 data/processed_files/train/trump.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCR8Abh3o3uT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "56475d72-04e7-4b6e-a3bf-a25abd1693fc"
      },
      "source": [
        "! sudo apt-get install git-lfs\n",
        "! git-lfs pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c917ql-3ojhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1a4a24ae-d8bd-4001-dc85-ddc2c7ae4df9"
      },
      "source": [
        "import pickle\n",
        "import csv\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
        "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME\n",
        "#from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear\n",
        "\n",
        "from bertviz.bertviz import attention, visualization\n",
        "from bertviz.bertviz.pytorch_pretrained_bert import BertModel, BertTokenizer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D66SD9ggojhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "bert_classifier_model_dir = \"models/\" ## Path of BERT classifier model path\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "logger.info(\"device: {}, n_gpu {}\".format(device, n_gpu))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mKJ70cOojh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file paths\n",
        "data_dir = os.getcwd()\n",
        "dataset = \"data\" # amazon / yelp / imagecaption\n",
        "train_0 = os.path.join(data_dir ,\"{}/train/trump.txt\".format(dataset))\n",
        "train_1 = os.path.join(data_dir,\"{}/train/en.txt\".format(dataset))\n",
        "test_0 = os.path.join(data_dir,\"{}/test/trump.txt\".format(dataset))\n",
        "test_1 = os.path.join(data_dir,\"{}/test/en.txt\".format(dataset))\n",
        "dev_0 = os.path.join(data_dir,\"{}/dev/trump.txt\".format(dataset))\n",
        "dev_1 = os.path.join(data_dir,\"{}/dev/en.txt\".format(dataset))\n",
        "reference_0 = os.path.join(data_dir,\"./{}/reference_0.txt\".format(dataset))\n",
        "reference_1 = os.path.join(data_dir,\"./{}/reference_1.txt\".format(dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSly4lIsojh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file paths\n",
        "data_dir = os.getcwd()\n",
        "dataset = \"data\" # amazon / yelp / imagecaption\n",
        "train_0_out = os.path.join(data_dir ,\"{}/processed_files/train/trump.txt\".format(dataset))\n",
        "train_1_out = os.path.join(data_dir,\"{}/processed_files/train/en.txt\".format(dataset))\n",
        "test_0_out = os.path.join(data_dir,\"{}/processed_files/test/trump.txt\".format(dataset))\n",
        "test_1_out = os.path.join(data_dir,\"{}/processed_files/test/en.txt\".format(dataset))\n",
        "dev_0_out = os.path.join(data_dir,\"{}/processed_files/dev/trump.txt\".format(dataset))\n",
        "dev_1_out = os.path.join(data_dir,\"{}/processed_files/dev/en.txt\".format(dataset))\n",
        "reference_0_out = os.path.join(data_dir,\"{}/processed_files/trump.txt\".format(dataset))\n",
        "reference_1_out = os.path.join(data_dir,\"{}/processed_files/en.txt\".format(dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsJ8m4igojh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64ceba85-f243-4025-f3eb-2747def457ab"
      },
      "source": [
        "## Model for performing Classification\n",
        "model_cls = BertForSequenceClassification.from_pretrained(bert_classifier_model_dir, num_labels=2)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model_cls.to(device)\n",
        "model_cls.eval()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyDmEmzmojh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de12d655-8b8c-4a43-835f-7da6949d2d17"
      },
      "source": [
        "## Model to get the attention weights of all the heads\n",
        "model = BertModel.from_pretrained(bert_classifier_model_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5hWKbLFojiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_len=70 # Maximum sequence length \n",
        "sm = torch.nn.Softmax(dim=-1) ## Softmax over the batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyndVUeIojiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "common_words=['is','are','was','were','has','have','had','a','an','the','this','that','these','those','there','how','i','we',\n",
        "             'he','she','it','they','them','their','his','him','her','us','our', 'and','in','my','your','you', 'will', 'shall']\n",
        "common_words_tokens = tokenizer.convert_tokens_to_ids(common_words)\n",
        "not_to_remove_ids = tokenizer.convert_tokens_to_ids([\"[CLS]\",\"[SEP]\", \".\", \"?\", \"!\"])\n",
        "not_to_remove_ids += common_words_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmfS2ASkojiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_file(file_path):\n",
        "    with open(file_path, encoding = \"ISO-8859-1\") as fp:\n",
        "        data = fp.read().splitlines()\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jTFRGqhojiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_output_file(original_sentences,processed_sentences, output_file, sentiment=\"<POS>\"):\n",
        "    with open(output_file,\"w\") as fp:\n",
        "        for sen1,sen2 in zip(original_sentences,processed_sentences):\n",
        "            if sen1 != None and sen2 != None:\n",
        "                str1 = sentiment + \" <CON_START> \" + sen2 + \" <START> \" + sen1 + \" <END>\\n\"\n",
        "                fp.write(str1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRkuYxqFojiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_ref_output_file(processed_sentences, output_file, sentiment=\"<POS>\"):\n",
        "    with open(output_file,\"w\") as fp:\n",
        "        for sen in tqdm(processed_sentences):\n",
        "            if sen != None:\n",
        "                str1 = sentiment + \" <CON_START> \" + sen + \" <START>\\n\"\n",
        "                fp.write(str1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVZ3DYrIojiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concate_files(inp_files, out_files):\n",
        "    with open(out_files,\"w\") as fp:\n",
        "        for file in inp_files:\n",
        "            with open(file) as f:\n",
        "                for line in f:\n",
        "                    fp.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N1jBn1TojiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_attn_examples(input_sentences, layer, head, bs=128):\n",
        "    \"\"\"\n",
        "    Returns Attention weights for selected Layer and Head along with ids and tokens\n",
        "    of the input_sentence\n",
        "    \"\"\"\n",
        "    ids = []\n",
        "    ids_to_decode = [None for k in range(len(input_sentences))]\n",
        "    tokens_to_decode = [None for k in range(len(input_sentences))]\n",
        "    segment_ids = []\n",
        "    input_masks = []\n",
        "    attention_weights = [None for z in input_sentences]\n",
        "    ## BERT pre-processing\n",
        "    for j,sen in enumerate(tqdm(input_sentences)):\n",
        "        \n",
        "        text_tokens = tokenizer.tokenize(sen)\n",
        "        if len(text_tokens) >= max_seq_len-2:\n",
        "            text_tokens = text_tokens[:max_seq_len-4]\n",
        "        tokens = [\"[CLS]\"] + text_tokens + [\"[SEP]\"]\n",
        "        tokens_to_decode[j] = tokens\n",
        "        temp_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        ids_to_decode[j] = temp_ids\n",
        "        input_mask = [1] * len(temp_ids)\n",
        "        segment_id = [0] * len(temp_ids)\n",
        "        padding = [0] * (max_seq_len - len(temp_ids))\n",
        "        \n",
        "        \n",
        "        temp_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_id += padding\n",
        "        \n",
        "        ids.append(temp_ids)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "    \n",
        "    # Convert Ids to Torch Tensors\n",
        "    ids = torch.tensor(ids) \n",
        "    segment_ids = torch.tensor(segment_ids)\n",
        "    input_masks = torch.tensor(input_masks)\n",
        "    \n",
        "    steps = len(ids) // bs\n",
        "    \n",
        "    for i in trange(steps+1):\n",
        "        if i == steps:\n",
        "            temp_ids = ids[i * bs : len(ids)]\n",
        "            temp_segment_ids = segment_ids[i * bs: len(ids)]\n",
        "            temp_input_masks = input_masks[i * bs: len(ids)]\n",
        "        else:\n",
        "            temp_ids = ids[i * bs : i * bs + bs]\n",
        "            temp_segment_ids = segment_ids[i * bs: i * bs + bs]\n",
        "            temp_input_masks = input_masks[i * bs: i * bs + bs]\n",
        "        \n",
        "        temp_ids = temp_ids.to(device)\n",
        "        temp_segment_ids = temp_segment_ids.to(device)\n",
        "        temp_input_masks = temp_input_masks.to(device)\n",
        "        with torch.no_grad():\n",
        "             _, _, attn = model(temp_ids, temp_segment_ids, temp_input_masks)\n",
        "        # Concate Attention weights\n",
        "        for j in range(len(attn[layer]['attn_probs'])):\n",
        "            attention_weights[i * bs + j] = (attn[layer]['attn_probs'][j][head][0]).to('cpu')\n",
        "    \n",
        "    return attention_weights, ids_to_decode, tokens_to_decode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvVoisefojiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(aw, ids_to_decode, tokens_to_decode):\n",
        "    out_sen = [None for i in range(len(aw))]\n",
        "    for i in trange(len(aw)):\n",
        "        #topv, topi = aw[i].topk(len(inps_tokens[i]))\n",
        "        topv, topi = aw[i].topk(ids_to_decode[i].index(0))\n",
        "        topi = topi.tolist()\n",
        "        topv = topv.tolist()\n",
        "        #print(i,train_0[i])\n",
        "        #print(tokens_to_decode[i])\n",
        "        #print(\"Original Top Indexes = {}\".format(topi))\n",
        "        topi = [topi[j] for j in range(len(topi)) if ids_to_decode[i][topi[j]] not in not_to_remove_ids] # remove noun and common words\n",
        "        #print(\"After removing Nouns = {}\".format(topi))\n",
        "        topi = [topi[j] for j in range(len(topi)) if \"##\" not in tokens_to_decode[i][topi[j]]] # Remove half words\n",
        "        #print(\"After removing Half-words = {}\".format(topi))\n",
        "\n",
        "        if (len(topi) < 4 and len(topi) > 0):\n",
        "            topi = [topi[0]]\n",
        "        elif(len(topi) < 8):\n",
        "            topi = topi[:2]\n",
        "        else:\n",
        "            topi = topi[:3]\n",
        "\n",
        "        #print(\"Final Topi = {}\".format(topi))\n",
        "        final_indexes = []\n",
        "        count = 0\n",
        "        count1 = 0\n",
        "        #print(ids_to_decode[i], tokens_to_decode[i])\n",
        "        while ids_to_decode[i][count] != 0:\n",
        "            if count in topi:\n",
        "                while ids_to_decode[i][count + count1 + 1] != 0:\n",
        "                    if \"##\" in tokens_to_decode[i][count + count1 + 1]:\n",
        "                        count1 += 1\n",
        "                    else:\n",
        "                        break\n",
        "                count += count1\n",
        "                count1 = 0\n",
        "            else:\n",
        "                final_indexes.append(ids_to_decode[i][count])\n",
        "            count += 1\n",
        "\n",
        "        #print(final_indexes)\n",
        "        temp_out_sen = tokenizer.convert_ids_to_tokens(final_indexes)\n",
        "        temp_out_sen = \" \".join(temp_out_sen).replace(\" ##\", \"\").replace(\"[CLS]\",\"\").replace(\"[SEP]\",\"\")\n",
        "        #print(temp_out_sen, \"\\n\\n\")\n",
        "        out_sen[i] = temp_out_sen.strip()\n",
        "    \n",
        "    return out_sen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXkFVLzqojiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_0_data = read_file(train_0)\n",
        "train_1_data = read_file(train_1)\n",
        "dev_0_data = read_file(dev_0)\n",
        "dev_1_data = read_file(dev_1)\n",
        "test_0_data = read_file(test_0)\n",
        "test_1_data = read_file(test_1)\n",
        "# ref_0_data = read_file(reference_0)\n",
        "# ref_1_data = read_file(reference_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpHHWJ0-ojiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9ffd6054-6d52-47f7-acb3-c7fc65493567"
      },
      "source": [
        "aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_0_data, layer=0, head=1, bs=128)\n",
        "train_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
        "create_output_file(train_0_data, train_0_out_sen, train_0_out, sentiment=\"<NEG>\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13711/13711 [00:16<00:00, 856.90it/s]\n",
            "100%|██████████| 108/108 [00:30<00:00,  3.57it/s]\n",
            "100%|██████████| 13711/13711 [00:01<00:00, 12876.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvMVjfLFojiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fc88494c-d668-46cd-f137-3c685d91641c"
      },
      "source": [
        "aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_1_data, layer=0, head=1, bs=128)\n",
        "train_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
        "create_output_file(train_1_data, train_1_out_sen, train_1_out, sentiment=\"<POS>\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18763/18763 [00:25<00:00, 744.85it/s]\n",
            "100%|██████████| 147/147 [00:41<00:00,  3.55it/s]\n",
            "100%|██████████| 18763/18763 [00:00<00:00, 18971.47it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7PVlBOJojiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "07643b9f-ac9d-4b75-b032-ca216a031fdc"
      },
      "source": [
        "aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_0_data, layer=0, head=1, bs=128)\n",
        "dev_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
        "create_output_file(dev_0_data, dev_0_out_sen, dev_0_out, sentiment=\"<NEG>\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1880/1880 [00:02<00:00, 872.65it/s]\n",
            "100%|██████████| 15/15 [00:04<00:00,  3.60it/s]\n",
            "100%|██████████| 1880/1880 [00:00<00:00, 12945.34it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeomWaTYojiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e4742f3d-7581-4550-d00e-b1c06c0ab5e1"
      },
      "source": [
        "aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_1_data, layer=0, head=1, bs=128)\n",
        "dev_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
        "create_output_file(dev_1_data, dev_1_out_sen, dev_1_out, sentiment=\"<POS>\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2587/2587 [00:03<00:00, 768.11it/s]\n",
            "100%|██████████| 21/21 [00:05<00:00,  3.68it/s]\n",
            "100%|██████████| 2587/2587 [00:00<00:00, 19640.21it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5L0-hqiojia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9bac650b-ab04-48d8-933e-92e4b59bda99"
      },
      "source": [
        "aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_1_data, layer=0, head=1, bs=128)\n",
        "test_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
        "create_output_file(test_1_data, test_1_out_sen, test_1_out, sentiment=\"<POS>\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 183266/183266 [00:35<00:00, 5126.02it/s]\n",
            "100%|██████████| 1432/1432 [06:44<00:00,  3.54it/s]\n",
            "100%|██████████| 183266/183266 [00:05<00:00, 32368.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGXk-vqaojib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f80d2cd2-cf04-4aba-88d3-43fc85182e48"
      },
      "source": [
        "aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_0_data, layer=0, head=1, bs=128)\n",
        "test_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
        "create_output_file(test_0_data, test_0_out_sen, test_0_out, sentiment=\"<NEG>\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 148/148 [00:00<00:00, 792.19it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.69it/s]\n",
            "100%|██████████| 148/148 [00:00<00:00, 11005.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahV_g2evojic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_1_data, layer=0, head=1, bs=128)\n",
        "# ref_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
        "# create_ref_output_file(ref_1_data, ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEWPzL5Sojie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_0_data, layer=0, head=1, bs=128)\n",
        "# ref_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n",
        "# create_ref_output_file(ref_0_data, ref_0_out_sen, reference_0_out, sentiment=\"<POS>\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcsFk2P9m9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fa9288c5-85e1-476d-83a6-a8c5dd44d322"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "! zip -r /content/file.zip /content/style-transfer/data/processed_files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/style-transfer/data/processed_files/ (stored 0%)\n",
            "  adding: content/style-transfer/data/processed_files/test/ (stored 0%)\n",
            "  adding: content/style-transfer/data/processed_files/test/en.txt (deflated 76%)\n",
            "  adding: content/style-transfer/data/processed_files/test/trump.txt (deflated 68%)\n",
            "  adding: content/style-transfer/data/processed_files/dev/ (stored 0%)\n",
            "  adding: content/style-transfer/data/processed_files/dev/en.txt (deflated 67%)\n",
            "  adding: content/style-transfer/data/processed_files/dev/trump.txt (deflated 69%)\n",
            "  adding: content/style-transfer/data/processed_files/train/ (stored 0%)\n",
            "  adding: content/style-transfer/data/processed_files/train/en.txt (deflated 67%)\n",
            "  adding: content/style-transfer/data/processed_files/train/trump.txt (deflated 69%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOdAzdxb99X3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}